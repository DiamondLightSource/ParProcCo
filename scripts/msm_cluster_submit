#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import annotations

import argparse
import logging
import os
from pathlib import Path
from typing import List

from ParProcCo.job_controller import JobController
from ParProcCo.msm_data_slicer import MSMDataSlicer
from ParProcCo.msm_processing_mode_interface import MSMProcessingModeInterface
from ParProcCo.msm_aggregation_mode_interface import MSMAggregationModeInterface


def create_parser():
    '''
     $ msm_cluster_submit rs_map --output cluster_output_dir --jobs --cores 6 --memory 4G -s 0.01 ... [input files]
     '''
    parser = argparse.ArgumentParser(description='Miller Space Mapper run script for use with ParProcCo')
    parser.add_argument('-o', '--output', help='str: cluster output directory', required=True)
    parser.add_argument('--jobs', help='int: number of cluster jobs to split processing into', type=int, default=1)
    parser.add_argument('--memory', help='str: memory to use per cluster job', required=True)
    parser.add_argument('--cores', help='int: number of cores to use per cluster job', type=int, required=True)
    return parser

def run_msm(args: argparse.Namespace, script_args: List) -> None:
    '''
    Run JobController
    '''
    beamline = os.getenv('BEAMLINE')
    if not beamline:
        raise ValueError('BEAMLINE environment variable not defined')
    cluster = os.getenv('SGE_CELL')
    if not cluster:
        raise ValueError('SGE_CELL environment variable not defined. Module load global/cluster or hamilton')
    if cluster == 'HAMILTON':
        cluster_queue = 'all.q'
        cluster_resources = None
    elif cluster == 'DLS_SCIENCE':
        from getpass import getuser
        if getuser() == 'gda2':
            cluster_queue = 'high.q'
            logging.debug('User is gda2 so using cluster queue {}', cluster_queue)
        else:
            cluster_queue = 'medium.q'
        cluster_resources = {"cpu_model": "intel-xeon"}
    else:
        raise ValueError('SGE_CELL value not known (HAMILTON or DLS_SCIENCE)')

    logging.info('Running for beamline {} on cluster {} in queue {} with resources {}', beamline, cluster, cluster_queue, cluster_resources)
    jc = JobController(args.output, beamline, cluster_queue, cluster_resources)
    args.jobs = int(args.jobs)
    args.cores = args.cores
    current_script_dir = Path(os.path.realpath(__file__)).parent
    runner_script_path = current_script_dir / "msm_cluster_runner"
    agg_runner_path = current_script_dir / "msm_cluster_runner"
    agg_script_path = str(current_script_dir / "msm_agg_jobscript")
    jc.run(MSMDataSlicer(), args.jobs, MSMProcessingModeInterface(), MSMAggregationModeInterface(), runner_script_path,
           agg_runner_path, script_args, [agg_script_path], args.memory, args.cores, "MSM")
    print("complete")


if __name__ == '__main__':
    args, script_args = create_parser().parse_known_args()
    run_msm(args, script_args)
